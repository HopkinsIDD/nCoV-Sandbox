---
title: 'Simple CFR approach'
output: html_document
---

```{r setup, include=FALSE}

#preamble
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "..")
 
require(knitr)
require(tidyverse)
require(gridExtra)
require(rstan)
require(splines2)
require(readr)
require(parallel)
require(mosaicCalc)
require(lubridate)
library(deSolve)

source("../R/DataLoadUtils.r")
source("../R/BasicEpiAnalyses.r")
source("../R/CFRutils.r")
source("../R/mle_utils_r.R")

```

## Goal
Here is the basic model. We are interested in estimating the CFR among confirmed 
cases, $\rho$. 

Presume that the time from confirmation to report of death (censoring at recovery) follows an arbitrary parametric distribution:
$$\Pr(Y_i<k) = F(k; \theta)$$

Where $Y_i$ is the time from confirmation to  death for person $i$ and $\theta$ is a vector of parameters required to define the parametric distribution..

Moreover, the time from confirmation to death or recovery (composite outcome) follows an exponential distribution:
$$\Pr(T_i<k) = G(k; \eta)$$
Where $T_i$ is the time from confirmation to  death or recovery for person $i$.



Let $d_{jt}$ be the number of new reported deaths in location $j$ on calendar date $t$. $d_{jt}$ depends on the hazard function for death over time since becoming a confirmed case and the distribution of infection duration on calendar date $t$.
$$E(d_{jt}) = \sum_{k=1}^t n_{jtk}h_{1k}$$

where $h_{1k}$ is the cause-specific hazard function for death over time since confirmation, and whose shape is determined by parameters $\theta$.


Let $r_{jt}$ be the number of new reported recoveries in location $j$ on calendar date $t$. $r_{jt}$ depends on the hazard function for recovery over time since becoming a confirmed case and the distribution of infection duration on calendar date $t$.
$$E(r_{jt}) = \sum_{k=1}^t n_{jtk}h_{2k}$$

where $h_{2k}$ is the cause-specific hazard function for recovery over time since confirmation, and whose shape is determined by parameters $\eta$.

For example, if we assume that $F{k}$ follows a Weibull distribution, $\theta = \{\lambda_1, \alpha_1\}$ and $h_{1k} = \alpha_1\lambda_1^{\alpha_1}k^{(\alpha_1-1)}$

To simplify estimation of $\rho$ in our dataset, which is organized by calendar date, we will first assume both time to death and time to recovery follow an exponential distirbution with a constant hazard functions, $\lambda_1$ and $\lambda_2$, respectively, for now. 

Based on the above:
$$E(d_{jt}) =  n_{jt} \lambda_1$$
where $n_{jt}$ is the number of currently infected people in the risk set on that day.
Similarly, let $r_{jt}$ be the number of new recoveries s in location $j$ on calendar date $t$. Based on the 
above:
$$E(r_{jt}) =  n_{jt} (\lambda_2) $$

Because there appear to be differences in mortality and recovery rates bewteen Hubei and elsewhere, we will write $\lambda_1$ and $\lamnbda_2$ as a function of location, such that $\lambda_1 = exp(\beta_0 + \beta_1 Hubei)$ and $\lambda_2 = exp(\gamma_0 + \gamma_1 Hubei)$.

### Data management
Prepare aggregate data on total cases, deaths, and recoveries by calendar date to be read into model.  

```{r message=FALSE, warning=FALSE, include=FALSE}
library(readr)
library(tidyverse)
#Load in the JHU CSSE Data
todaydate <- ISOdate(2020,4,30, hour = 11, min = 59, tz = "UTC")
cfr_moddata_all <- moddata_country(todaydate)
cfr_moddata <-cfr_moddata_all[[1]]
locs <- cfr_moddata_all[[2]] #get lookup table

#prepare individual-level data
date <-ymd("20200305")
IndDat <- read_MK_linelist("3-5-2020")
IndDat <- process_MK_linelist(IndDat, ymd(date))


IndDat <- IndDat %>% 
            mutate(t = ifelse(t<=0, 1, t)) %>% 
            mutate(country=replace(country, country=="United States", "US")) %>%
            mutate(country=replace(country, country=="United Kingdom", "UK")) %>%
            mutate(country=replace(country, country=="China", "Mainland China")) %>%
            mutate(country2 = ifelse((province == "Hubei" & !is.na(province)) | is.na(country), province, country)) %>% 
            mutate(loc = locs[country2]) %>% 
            mutate(w = ifelse(country == "US", 1, 0))
          

deaths <- IndDat %>% filter(delta == 1 & !is.na(t) & t>1) %>% select(t, country2, loc)
recovs <-   IndDat %>% filter(delta == 2& !is.na(t)& t>1) %>% select(t, country2, loc)

td <- deaths$t
wdi <- deaths$loc
tr <- recovs$t
wri <- recovs$loc

cfr_moddata$tr <- tr
cfr_moddata$td <- ifelse(td>nrow(cfr_moddata$c), nrow(cfr_moddata$c), td)
cfr_moddata$wdi <- wdi
cfr_moddata$wri <- wri
cfr_moddata$Nd <- length(td)
cfr_moddata$Nr <- length(tr)


naive <- sum(cfr_moddata$d)/sum(cfr_moddata$d+cfr_moddata$r)

#make some plots to double check that data looks ok
#confirmed
ys <- NULL

 for(i in 1:ncol(cfr_moddata$c)){
  ys <- c(ys, cfr_moddata$c[,i])
}
test <- data.frame(x= rep(c(1:cfr_moddata$T), ncol(cfr_moddata$c)), loc = rep(1:ncol(cfr_moddata$c), each = cfr_moddata$T), y=ys)

ggplot(test, aes(x=x, y=ys, colour = loc, group=loc))+
  geom_line()

#deaths
ys <- NULL

 for(i in 1:ncol(cfr_moddata$d)){
  ys <- c(ys, cfr_moddata$d[,i])
}
test <- data.frame(x= rep(c(1:cfr_moddata$T), ncol(cfr_moddata$d)), loc = rep(1:ncol(cfr_moddata$d), each = cfr_moddata$T), y=ys)

ggplot(test, aes(x=x, y=ys, colour = loc, group=loc))+
  geom_line()


#recovs
ys <- NULL

 for(i in 1:ncol(cfr_moddata$d)){
  ys <- c(ys, cfr_moddata$r[,i])
}
test <- data.frame(x= rep(c(1:cfr_moddata$T), ncol(cfr_moddata$r)), loc = rep(1:ncol(cfr_moddata$r), each = cfr_moddata$T), y=ys)

ggplot(test, aes(x=x, y=ys, colour = loc, group=loc))+
  geom_line()


```

## First, fit maximum likelihood estimators

First run exponential model with maximum likelihood (with aggregate + individual data)
```{r}

test <- cfrbounds(cfr_moddata)
test
#starting values
b <- c(log(0.001), log(0.01), 0)
exp.mdl <- optim(b, LLexp.ind, data = cfr_moddata, recovrate = "estimate")
exp(exp.mdl$par)
lambda1 <- exp(exp.mdl$par)[1]
lambda2 <- exp(exp.mdl$par)[2]
dr <- expit(exp.mdl$par)[3]
 rho <- integrate(function(x) {   
                                          risk.Inf <- lambda1*exp(- ((lambda1*x +lambda2*x)))
                                          return(risk.Inf)
    },
                        lower = 0, upper =Inf)$value
rho

```


Then, run weibull model model with maximum likelihood (with aggregate + individual data)
```{r}
#starting values
b <- c(log(0.001), log(0.01), 0, 0, 0)
wbl.mdl <- optim(b, LLwbl.ind, data = cfr_moddata, recovrate = "estimate")
exp(wbl.mdl$par)
lambda1 <- exp(wbl.mdl$par)[1]
lambda2 <- exp(wbl.mdl$par)[2]
alpha1 <- exp(wbl.mdl$par)[3]
alpha2 <- exp(wbl.mdl$par)[4]
dr <- expit(wbl.mdl$par)[5]
  rho <- integrate(function(x) risk.Inf <- alpha1*lambda1*x^(alpha1-1) * 
                     exp((-(lambda1*x^(alpha1) +lambda2*x^(alpha2)))),
                   lower = 0, upper =Inf)$value
rho

```

Compartmental model with maximum likelihood
```{r}
 # some nested functions 
  dx.dt <- function (t, state, param, N=3) {
    rc <- vector(length=N+2)
    rc[N+1] <- 0
    rc[N+2] <- 0
    
    for (i in 1:N) {
      ##add from last state if not 1
      rc[i] <- ifelse(i>1, state[i-1]*param[1], 0) 
      ## Take out deaths and recoverds
      rc[i] <- rc[i] - (param[i+1] + param[N+i+1])*state[i]
      ##Move to next state if not N
      if (i<N) {rc[i] <- rc[i]-param[1]*state[i]}
      ##Decrement deaths and revoverds
      rc[N+1] <- rc[N+1] + param[i+1]*state[i]
      rc[N+2] <- rc[N+2] + param[N+i+1]*state[i]
    }
    
    return(list(rc))
  }
  
  solve_deaths <- function(alpha, lambda1s, lambda2s, N) {
    res <- ode(c(1, rep(0, N+1)), #initial state for N compartments plus death/recovery
               c(1,1000), #just need intial values and at T large
               dx.dt, #function
               c(alpha, lambda1s, lambda2s)
    )
    
    return(res[2,N+2]) #should be deaths
  }
  
  # Checking whether include_individual_data and deciding LL formula
  compartments <- 3
init_params=c(log(0.01), log(0.01), log(0.05), 0)
  init_params_c <- c(rep(init_params[1], compartments), rep(init_params[2], compartments), init_params[3], init_params[4])
  
  est_param <- optim(init_params_c, LLerlang.ind, data=cfr_moddata, compartments = compartments, hessian=F, recovrate="estimate")
  # est_lambda_ci <- sqrt(diag(solve(est_param$hessian)))  # might need this later for CFR 95% CL
  
  lambda1 <- exp(est_param$par[1:compartments])
  lambda2 <- exp(est_param$par[(compartments+1):(2*compartments)])
  alpha <- exp(est_param$par[compartments*2+1])
  dr <- expit(est_param$par[compartments*2+2])
  ##Translate this into estimates of the CFR, rho
  rho <- solve_deaths(alpha, lambda1, lambda2, N=compartments)
  
  rho
```


## Assuming constant hazards of death and recovery
### Stan models
First, define the stan model assuming constant hazards for death and recovery over time.

```{stan, eval = FALSE, output.var="cfrmdl_exp"}


// Input data 
data {
  int <lower=0> T; //the number of time steps included
  int <lower=0> L; //the number of locations we have data from
  int <lower = 0> V; // max infection duration (may not be needed)
  int <lower=0> r[T,L]; //  number of recovered cases reported on each day.
  int <lower=0> d[T,L]; //  number of deaths reported on each day. 
  real <lower=0> c[T,L]; //number of new cases  on each day. 
  int w[L]; //is this wuhan
  int Nd; // number of indiviudal-level deaths
  int Nr; // number of individual-level recoveries
  //vector[Nd] wdi; // indicator of living in hubei for individual deaths
 // vector[Nr] wri; // indicator of living in hubei for individual recoveries
  int wdi[Nd]; // indicator of living in hubei for individual deaths
  int wri[Nr]; // indicator of living in hubei for individual recoveries
  int td[Nd]; // time to each individual deaths
  int tr[Nr]; //time to each individual recoveries
}

parameters {
  real loglambda1; //parameter for time to death distribution
  real loglambda2; // parameter for time to death or recovery distribution
  real delta1_hubei; //parameter for diff in hubei's lambda1
  real delta2_hubei; // parameter for diff in hubei's lambda2
}

transformed parameters {
  real <lower=0> expected_deaths[T,L]; //  # deaths at time T
  real <lower=0> expected_recovereds[T,L]; //  # those who have exited due to recovery at T
  matrix[T,L] expected_riskset; //expected risk set on each day of inf dur
  real <lower=0> h1;
  real <lower=0> h2;
  
 expected_riskset = rep_matrix(0.0, T,L);  // initialize expected_riskset to all 0s;
  for (j in 1:L) {
 
    h1 = exp(loglambda1 + delta1_hubei*w[j]);
    h2 = exp(loglambda2 + delta2_hubei*w[j]);
    expected_riskset[1,j] = c[1,j]; //risk set on day 1 at inf duration 1 is just c1
    expected_deaths[1,j] = expected_riskset[1,j] * h1  ;
    expected_recovereds[1,j] = expected_riskset[1,j] * h2 ;
 
    for (t in 2:T) {
      expected_riskset[t,j] = (expected_riskset[t-1,j] + c[t,j] - (expected_riskset[t-1,j]*h1 +  (expected_riskset[t-1,j]* h2)));
      expected_deaths[t,j] = expected_riskset[t,j] *  h1  ;
      expected_recovereds[t,j] = expected_riskset[t,j] *  h2 ;
    } 
  }
}

model {
  //definitely can be made more effcient.
  //aggregate data
  for (j in 1:L) { 
    for (t in 1:T) {
      target+=poisson_lpmf(d[t,j]|expected_deaths[t,j]) + poisson_lpmf(r[t,j]|expected_recovereds[t,j]);
    }
  }
  //individual data
    for (g in 1:Nd) {
      target+=log(exp(loglambda1+wdi[g]*delta1_hubei)*exp(-(exp(loglambda1+wdi[g]*delta1_hubei)+exp(loglambda2+wdi[g]*delta2_hubei))*(td[g]))) ;//log(h1(t)*S(t-))
      }
    for (h in 1:Nr){
       target+=log(exp(loglambda2+wri[h]*delta2_hubei)*exp(-(exp(loglambda1+wri[h]*delta1_hubei)+exp(loglambda2+wri[h]*delta2_hubei))*(tr[h]))) ; //log(h2(t)*S(t-))
    }
}


```

Exponential model with random effect

```{stan, eval = FALSE, output.var="cfrmdl_exp_rand"}
data {
  int <lower=0> T; //the number of time steps included
  int <lower=0> L; //the number of locations we have data from
  int <lower = 0> V; // max infection duration (may not be needed)
  int <lower=0> r[T,L]; //  number of recovered cases reported on each day.
  int <lower=0> d[T,L]; //  number of deaths reported on each day. 
  real <lower=0> c[T,L]; //number of new cases  on each day. 
  int w[L]; //is this wuhan
  int Nd; // number of indiviudal-level deaths
  int Nr; // number of individual-level recoveries
  //vector[Nd] wdi; // indicator of living in hubei for individual deaths
  // vector[Nr] wri; // indicator of living in hubei for individual recoveries
  int wdi[Nd]; // indicator of living in hubei for individual deaths
  int wri[Nr]; // indicator of living in hubei for individual recoveries
  int td[Nd]; // time to each individual deaths
  int tr[Nr]; //time to each individual recoveries
}

parameters {
  real loglambda1i[L]; //parameter for time to death distribution for each location
  real loglambda2i[L]; // parameter for time to death or recovery distribution for each location
  real loglambda1; // parameter for time to death overall
  real loglambda2; // patmeter for tiem to recovery overall
  real<lower=0> tau1; // variance bewteen countries
  real<lower=0> tau2; // variance bewteen countries
  
}
transformed parameters {
  real <lower=0> expected_deaths[T,L]; //  # deaths at time T
    real <lower=0> expected_recovereds[T,L]; //  # those who have exited due to recovery at T
      matrix[T,L] expected_riskset; //expected risk set on each day of inf dur
    real <lower=0> h1;
    real <lower=0> h2;
    
    
    
    expected_riskset = rep_matrix(0.0, T,L);  // initialize expected_riskset to all 0s;
    for (j in 1:L) {
      
      h1 = exp(loglambda1i[j]);
      h2 = exp(loglambda2i[j]);
      
      
      expected_riskset[1,j] = c[1,j]; //risk set on day 1 at inf duration 1 is just c1
      expected_deaths[1,j] = expected_riskset[1,j] * h1  ;
      expected_recovereds[1,j] = expected_riskset[1,j] * h2 ;
      
      
      for (t in 2:T) {
        expected_riskset[t,j] = (expected_riskset[t-1,j] + c[t,j] - (expected_riskset[t-1,j]*h1 +  (expected_riskset[t-1,j]* h2)));
        expected_deaths[t,j] = expected_riskset[t,j] *  h1  ;
        expected_recovereds[t,j] = expected_riskset[t,j] *  h2 ;
      } 
    }
    
    
}

model {
  //definitely can be made more effcient.
  //aggregate data
  loglambda1i ~ normal(loglambda1, tau1);
  loglambda2i ~ normal(loglambda2, tau2);
  for (j in 1:L) { 
    for (t in 1:T) {
      target+=poisson_lpmf(d[t,j]|expected_deaths[t,j]) + poisson_lpmf(r[t,j]|expected_recovereds[t,j]);
    }
  }
  //individual data
  for (g in 1:Nd) {
    target+=log(exp(loglambda1i[wdi[g]])*exp(-(exp(loglambda1i[wdi[g]])+exp(loglambda2i[wdi[g]]))*(td[g]))) ;//log(h1(t)*S(t-))
  }
  for (h in 1:Nr){
    target+=log(exp(loglambda2i[wri[h]])*exp(-(exp(loglambda1i[wri[h]])+exp(loglambda2i[wri[h]]))*(tr[h]))) ; //log(h2(t)*S(t-))
  }
  
}


```




### Run Exponential model

First run exponential model with maximum likelihood (with aggregate + individual data)
```{r}
#starting values
b <- c(log(0.001), log(0.01))
exp.mdl <- optim(b, LLexp.ind, data = cfr_moddata)
exp(exp.mdl$par)
lambda1 <- exp(exp.mdl$par)[1]
lambda2 <- exp(exp.mdl$par)[2]
 rho <- integrate(function(x) {   
                                          risk.Inf <- lambda1*exp(- ((lambda1*x +lambda2*x)))
                                          return(risk.Inf)
    },
                        lower = 0, upper =Inf)$value
rho

```

Now run exponential with MCMC

```{r, eval = FALSE}
  cfrmdl_res_ex <- sampling(cfrmdl_exp, data=cfr_moddata,
                         iter=200, cores = 4, chains = 4)
  chains <- extract(cfrmdl_res_ex)
  lambda1 <- exp(chains$loglambda1)
  lambda2 <- exp(chains$loglambda2)
  lambda1_hubei <- exp(chains$loglambda1 + chains$delta1_hubei)
  lambda2_hubei <- exp(chains$loglambda2 + chains$delta2_hubei)
  
  outdat <- data.frame(lambda1 = lambda1, lambda2 = lambda2, lambda1_hubei = lambda1_hubei, lambda2_hubei = lambda2_hubei)
  
  #save(outdat, file = "data/outdat.RData")

```

### Summarize Exponential model


```{r, echo = FALSE }
#load("data/outdat.RData")

lambda2 <- outdat[,2]
lambda1 <- outdat[,1] 
lambda2_hubei <- outdat[,4]
lambda1_hubei <- outdat[,3] 

# plots about lambda (turn on if necessary)
# plot(density(lambda1), xlim=c(0,.1), type = "l")
#  lines(density(lambda2))
#  plot(lambda2, type = "l")
#  plot(lambda1, type = "l")
 
 rho <- matrix(nrow = length(lambda1))
 #estimate rho outside hubei
for(i in 1:length(lambda1)){
    F <- antiD( ((h1 )  *  exp(-(( (h1) + (h2))  * x)))~x, h1 = lambda1[i], h2 = lambda2[i])
    rho[i] = F(x=Inf) - F(x=0)
}
rho <- rho[!is.na(rho)]
median(rho)

rho_exp <- matrix(nrow = length(lambda1))

 for(i in 1:length(lambda1)){
  try (
    rho_exp[i] <- integrate(function(x) {   
                                          risk.Inf <- lambda1[i]*exp(- ((lambda1[i]*x +lambda2[i]*x)))
                                          return(risk.Inf)
    },
                        lower = 0, upper =Inf)$value)
}

rho_exp <- rho_exp[!is.na(rho_exp)]
median(rho_exp)
quantile(rho_exp, probs = c(.025, .975))


 #then estimate rho for hubei
 rho_hubei <- matrix(nrow = length(lambda1_hubei))

 #estimate rho outside hubei
for(i in 1:length(lambda1_hubei)){
    F <- antiD( ((h1 )  *  exp(-(( (h1) + (h2))  * x)))~x, h1 = lambda1_hubei[i], h2 = lambda2_hubei[i])
    rho_hubei[i] = F(x=Inf) - F(x=0)
}
rho_hubei <- rho_hubei[!is.na(rho_hubei)]
median(rho_hubei)

# 
# for(i in 1:length(lambda1)){
# 
#   try (
#     rho_hubei[i] <- integrate(function(x) {lambda1_hubei[i]*exp(-((lambda1_hubei[i]+lambda2_hubei[i])*x))}, 
#                         lower = 0, upper = Inf)$value)
# }
# 
# 
# rho_hubei <- rho_hubei[!is.na(rho_hubei)]
# median(rho_hubei)
quantile(rho_hubei, probs = c(.025, .975))
# plot(density(rho_hubei))
 plot((lambda1), type = "l")

```


The following code runs the above exponential model with the random effect

```{r}
initval <- function(){
  loglambda1i <- rep(-6, cfr_moddata$L)
  loglambda2i <- rep(-6, cfr_moddata$L)
  tau1 <- 0.001
  tau2 <- 0.001
    params <- list(loglambda1i=loglambda1i, loglambda2i=loglambda2i, loglambda1 = loglambda1i[1], loglambda2 = loglambda2i[1], tau1 = tau1, tau2=tau2)
    params
    #list(params, params, params, params)
}
cfrmdl_exp<- sampling(cfrmdl_exp_rand, data=cfr_moddata,
                         iter=200, cores = detectCores(), verbose = FALSE, init=initval)
chains <- rstan::extract(cfrmdl_exp)
lambda1 <- exp(chains$loglambda1)
lambda2 <- exp(chains$loglambda2)
lambda1i <- exp(chains$loglambda1i)
lambda2i <- exp(chains$loglambda2i)
alpha1 <- 1
alpha2 <- 1


```


this code computes the CFR

```{r, echo = FALSE }

#overall CFR
rho <- matrix(nrow = length(lambda1))

 for(i in 1:length(lambda1)){
  try (
    rho[i] <- integrate(function(x) {   
                                          risk.Inf <- lambda1[i]*exp(- ((lambda1[i]*x +lambda2[i]*x)))
                                          return(risk.Inf)
    },
                        lower = 0, upper =Inf)$value)
}


median(rho)
quantile(rho, probs = c(.025, .975))


#CFR by location

selectedlocs <- vector(length = cfr_moddata$L)
rhoi <- matrix(nrow=length(lambda1), ncol = length(selectedlocs))
for(j in 1:cfr_moddata$L){
  for(i in 1:length(lambda1i[,j])){
  try (
    rhoi[i,j] <- integrate(function(x) {   
                                          risk.Inf <- lambda1i[i,j]*exp(- ((lambda1i[i,j]*x +lambda2i[i,j]*x)))
                                          return(risk.Inf)
    },
                        lower = 0, upper =Inf)$value)
}
}

rhoj <- vector(length = cfr_moddata$L)
for(j in 1:cfr_moddata$L){
  rhoj[j] <- median(rhoi[,j])
}
names(rhoj) <- names(locs[-c(189)])
rhoj

```

## Allow hazard to vary by day of infection

### Stan model for Weibull

Now, attempt to allow hazards to vary over time assuming times to death and recovery follow Weibull distributions
```{stan, eval = FALSE, output.var="cfrmdl_wbl"}

data {
  int <lower=0> T; //the number of time steps included
  int <lower=0> L; //the number of locations we have data from
  int <lower = 0> V; // max infection duration (may not be needed)
  int <lower=0> r[T,L]; //  number of recovered cases reported on each day.
  int <lower=0> d[T,L]; //  number of deaths reported on each day. 
  real <lower=0> c[T,L]; //number of new cases  on each day. 
  int w[L]; //is this wuhan
    int Nd; // number of indiviudal-level deaths
  int Nr; // number of individual-level recoveries
  //vector[Nd] wdi; // indicator of living in hubei for individual deaths
  //vector[Nr] wri; // indicator of living in hubei for individual recoveries
  real whd[Nd]; // indicator of living in hubei for individual deaths
  real whr[Nr]; // indicator of living in hubei for individual recoveries
  int td[Nd]; // time to each individual deaths
  int tr[Nr]; //time to each individual recoveries
}

parameters {
  real loglambda1; //parameter for time to death distribution
  real loglambda2; // parameter for time to death or recovery distribution
  real delta1_hubei; //parameter for diff in hubei's lambda1
  real delta2_hubei; // parameter for diff in hubei's lambda2
  real  logalpha1; //parameter for time to death distribution
  real  logalpha2; // parameter for time to death or recovery distribution

}
transformed parameters {
  real <lower=0> expected_deaths[T,L]; //  # deaths at time T
  real <lower=0> expected_recovereds[T,L]; //  # those who have exited due to recovery at T
  matrix[V,T] expected_riskset; //expected risk set on each day of inf dur
  vector[V] h1;
  vector[V] h2;
  real <lower=0> alpha1; //parameter for time to death distribution
 real <lower=0> alpha2; // parameter for time to death or recovery distribution
//  vector[Nd] lambda1i; // lambda1 for each individual-level death
//  vector[Nr] lambda2i; //lmabda2 for each individual-level recovery
//  real <lower=0> indiv_expected_risk[V]; //looking a very long way out where would we expect an individual to be
//  real <lower=0> indiv_expect_death [V]; //what is an indivduals probability of dying on exactly each day
//  real <lower=0> indiv_expect_recover [V]; //what is an individauls probability of recovering on each day

  alpha1 = exp(logalpha1);
  alpha2 = exp(logalpha2);



for (j in 1:L) {
   expected_riskset = rep_matrix(0.0, V, T);  // initialize expected_riskset to all 0s;
  h1 = rep_vector(0, V);
  h2 = rep_vector(0, V);
  for(h in 1:V){ //pre-compute hazards at each time (do dno't have to do within each loop!)
    h1[h] = alpha1*exp(loglambda1 + delta1_hubei*w[j])*h^(alpha1-1);
    h2[h] = alpha2*exp(loglambda2 + delta2_hubei*w[j])*h^(alpha2-1);
  } 

    expected_riskset[1,1] = c[1,j]+0.0001; //risk set on day 1 at inf duration 1 is just c1
    expected_deaths[1,j] = expected_riskset[1,1] * h1[1] + 0.0001 ;
    expected_recovereds[1,j] = expected_riskset[1,1] * h2[1] + 0.0001;
 

    for (t in 2:T) {
      expected_riskset[1,t] = c[t,j]+0.0001;
      expected_deaths[t,j] = expected_riskset[1,t] *  h1[1] + 0.0001 ;
      expected_recovereds[t,j] = expected_riskset[1,t] *  h2[1] + 0.0001;
      
      for(k in 2:t){
      
        expected_riskset[k,t] = (expected_riskset[k-1,t-1] - (expected_riskset[k-1,t-1]*h1[k-1] +  (expected_riskset[k-1,t-1]* h2[k-1])));
        expected_deaths[t,j] +=  (expected_riskset[k,t] * h1[k]);
        expected_recovereds[t,j] += (expected_riskset[k,t] * h2[k]);

      }
    }
  }

}





model {
  //definitely can be made more effcient.
  //aggregate data
  for (j in 1:L) { 
    for (t in 1:T) {
      target+=poisson_lpmf(d[t,j]|expected_deaths[t,j]) + poisson_lpmf(r[t,j]|expected_recovereds[t,j]);
    }
  }
  //individual data
    for (g in 1:Nd) {
      target+=log(alpha1*exp(loglambda1 + delta1_hubei*whd[g]) * td[g]^(alpha1-1) *exp(-(exp(loglambda1 + delta1_hubei*whd[g])*td[g]^alpha1+exp(loglambda2 + delta2_hubei*whd[g])*td[g]^alpha2)));//log(h1(t)*S(t-))
      }
    for (h in 1:Nr){
     //target+= log(indiv_expect_recover[tr[h]]);
      target+=log(alpha2*exp(loglambda2 + delta2_hubei*whr[h])*tr[h]^(alpha2-1)*exp(-(exp(loglambda1 + delta1_hubei*whr[h])*tr[h]^alpha1+exp(loglambda2 + delta2_hubei*whr[h])*tr[h]^alpha2)));
    }


}

```
### Run Weibull model

```{r, eval = FALSE}
cfr_moddata$whd <- as.numeric(cfr_moddata$wdi == 90) #indicator "is this hubei" (need to fix this because will change as countries are added)
cfr_moddata$whr <- as.numeric(cfr_moddata$wri == 90)
 cfrmdl_res_Wbl <- sampling(cfrmdl_wbl, data=cfr_moddata,
                         iter=200, cores = 4, init=initval, verbose = FALSE)
  chains <- rstan::extract(cfrmdl_res_Wbl)
  lambda1 <- exp(chains$loglambda1)
  lambda2 <- exp(chains$loglambda2)
  lambda1_hubei <- exp(chains$loglambda1 + chains$delta1_hubei)
 lambda2_hubei <- exp(chains$loglambda2 + chains$delta2_hubei)

  alpha1 <- chains$alpha1
  alpha2 <- chains$alpha2

```

summarize
```{r, echo = FALSE }

#not  hubei
rho <- matrix(nrow = length(lambda1))

 for(i in 101:length(lambda1)){
  try (
    rho[i] <- integrate(function(x) {   
                                            risk.Inf <- alpha1[i]*lambda1[i]*x^(alpha1[i]-1)*exp(- ((lambda1[i]*x^(alpha1[i]) +lambda2[i]*x^(alpha2[i]))))
                                          return(risk.Inf)
    },
                        lower = 0, upper =Inf)$value)
}

rho
median(rho)
quantile(rho, probs = c(.025, .975))
 plot((lambda1), type = "l")
```

Weibull model with random effect for lambda (shared alphas)
```{stan, eval = FALSE, output.var="cfrmdl_wbl_r"}

data {
  int <lower=0> T; //the number of time steps included
  int <lower=0> L; //the number of locations we have data from
  int <lower = 0> V; // max infection duration (may not be needed)
  int <lower=0> r[T,L]; //  number of recovered cases reported on each day.
  int <lower=0> d[T,L]; //  number of deaths reported on each day. 
  real <lower=0> c[T,L]; //number of new cases  on each day. 
 // int w[L]; //is this hubei province
  int Nd; // number of indiviudal-level deaths
  int Nr; // number of individual-level recoveries
  int wdi[Nd]; // indicator of living in hubei for individual deaths
  int wri[Nr]; // indicator of living in hubei for individual recoveries
  int td[Nd]; // time to each individual deaths
  int tr[Nr]; //time to each individual recoveries
}

parameters {
  real loglambda1; //parameter for time to death distribution
  real loglambda2; // parameter for time to death or recovery distribution
  real loglambda1i[L]; //parameter for time to death distribution
  real loglambda2i[L]; // parameter for time to death or recovery distribution
 // real delta1_hubei; //parameter for diff in hubei's lambda1
 // real delta2_hubei; // parameter for diff in hubei's lambda2
  real  logalpha1; //parameter for time to death distribution (shared)
  real  logalpha2; // parameter for time to death or recovery distribution (shared)
  real<lower=0> tau1;
  real<lower=0> tau2;
}
transformed parameters {
  real <lower=0> expected_deaths[T,L]; //  # deaths at time T
  real <lower=0> expected_recovereds[T,L]; //  # those who have exited due to recovery at T
  matrix[V,T] expected_riskset; //expected risk set on each day of inf dur
  vector[V] h1;
  vector[V] h2;
  real <lower=0> alpha1; //parameter for time to death distribution
 real <lower=0> alpha2; // parameter for time to death or recovery distribution

  alpha1 = exp(logalpha1);
  alpha2 = exp(logalpha2);

for (j in 1:L) {
  expected_riskset = rep_matrix(0.0, V, T);  // initialize expected_riskset to all 0s;
  h1 = rep_vector(0, V);
  h2 = rep_vector(0, V);
  for(h in 1:V){ //pre-compute hazards at each time (do dno't have to do within each loop!)
    h1[h] = alpha1*exp(loglambda1i[j])*h^(alpha1-1);
    h2[h] = alpha2*exp(loglambda2i[j])*h^(alpha2-1);
  } 

    expected_riskset[1,1] = c[1,j]+0.001; //risk set on day 1 at inf duration 1 is just c1
    expected_deaths[1,j] = expected_riskset[1,1] * h1[1]  ;
    expected_recovereds[1,j] = expected_riskset[1,1] * h2[1] ;
 

    for (t in 2:T) {
      expected_riskset[1,t] = c[t,j]+0.001;
      expected_deaths[t,j] = expected_riskset[1,t] *  h1[1] ;
      expected_recovereds[t,j] = expected_riskset[1,t] *  h2[1] ;
      
      for(k in 2:t){
      
        expected_riskset[k,t] = (expected_riskset[k-1,t-1] - (expected_riskset[k-1,t-1]*h1[k-1] +  (expected_riskset[k-1,t-1]* h2[k-1])));
        expected_deaths[t,j] +=  (expected_riskset[k,t] * h1[k]);
        expected_recovereds[t,j] += (expected_riskset[k,t] * h2[k]);

      }
    }
  }

}

model {
  //definitely can be made more effcient.
  //aggregate data
  
  loglambda1i ~ normal(loglambda1, tau1);
  loglambda2i ~ normal(loglambda2, tau2);
  for (j in 1:L) { 
    for (t in 1:T) {
      target+=poisson_lpmf(d[t,j]|expected_deaths[t,j]) + poisson_lpmf(r[t,j]|expected_recovereds[t,j]);
    }
  }
  //individual data
    for (g in 1:Nd) {
      target+=log(alpha1*exp(loglambda1i[wdi[g]]) * td[g]^(alpha1-1) * exp(-( exp(loglambda1i[wdi[g]])*td[g]^alpha1+exp(loglambda2i[wdi[g]])*td[g]^alpha2) ));//log(h1(t)*S(t-))
      }
    for (h in 1:Nr){
      target+=log(alpha2*exp(loglambda2i[wri[h]])*tr[h]^(alpha2-1)*exp(-(exp(loglambda1i[wri[h]])*tr[h]^alpha1+exp(loglambda2i[wri[h]])*tr[h]^alpha2)));
    }
}

```

### Run Weibull model

```{r, eval = FALSE}
#cfr_moddata$dr <- cfr_moddata$d+cfr_moddata$r
# initval <- function(){
#   l1 <- .001
#   l2 <- .05
#   a1 <- 0.5
#   a2 <- 0.5
#     params <- list(loglambda1=log(l1), loglambda2=log(l2), logalpha1=log(a1), logalpha2 = log(a2), delta_death_hubei = 0, delta_recover_hubei=0)
#     params
#     #list(params, params, params, params)
# }
# 
# initval() 
initval <- function(){
  loglambda1i <- rep(log(0.001), cfr_moddata$L)
  loglambda2i <- rep(log(0.005), cfr_moddata$L)
  logalpha1i <- rep(log(1), cfr_moddata$L)
  logalpha2i <- rep(log(1), cfr_moddata$L)
  tau1 <- 1
  tau2 <- 1
  sig1 <- 1
  sig2 <- 1
    params <- list(loglambda1i=loglambda1i, loglambda2i=loglambda2i, loglambda1 = loglambda1i[1], loglambda2 = loglambda2i[1], tau1 = tau1, tau2=tau2, logalpha1=0, logalpha2=0)#, sig1 = 1, sig2 = 1)
    params
}

# initval <- function(){
#   loglambda1i <- rep(-6, cfr_moddata$L)
#   loglambda2i <- rep(log(0.05), cfr_moddata$L)
#   tau1 <- 0.01
#   tau2 <- 0.01
#     params <- list(loglambda1i=loglambda1i, loglambda2i=loglambda2i, loglambda1 = loglambda1i[1], loglambda2 = loglambda2i[1], tau1 = tau1, tau2=tau2, logalpha1=0, logalpha2=0)
#     params
# }

 cfrmdl_res_Wbl <- sampling(cfrmdl_wbl_r, data=cfr_moddata,
                         iter=150, cores = 4, init=initval, verbose = FALSE)
  chains <- rstan::extract(cfrmdl_res_Wbl)
  lambda1 <- exp(chains$loglambda1)
  lambda2 <- exp(chains$loglambda2)
  lambda1i <- exp(chains$loglambda1i)
  lambda2i <- exp(chains$loglambda2i)
 #  lambda1_hubei <- exp(chains$loglambda1 + chains$delta1_hubei)
 # lambda2_hubei <- exp(chains$loglambda2 + chains$delta2_hubei)

  alpha1 <- chains$alpha1
  alpha2 <- chains$alpha2

```

### Summarize Weibull model

```{r, echo = FALSE }
# load("data/outdat_wbl.RData")
# 
# lambda2 <- outdat_wbl[,2]
# lambda1 <- outdat_wbl[,1] 
# lambda2_hubei <- outdat_wbl[,4]
# lambda1_hubei <- outdat_wbl[,3] 
# alpha1 <- outdat_wbl[,5]
# alpha2 <- outdat_wbl[,6]


rho <- matrix(nrow = length(lambda1))

 for(i in 1:length(lambda1)){
  try (
    rho[i] <- integrate(function(x) {   
                                            risk.Inf <- alpha1[i]*lambda1[i]*x^(alpha1[i]-1)*exp(- ((lambda1[i]*x^(alpha1[i]) +lambda2[i]*x^(alpha2[i]))))
                                          return(risk.Inf)
    },
                        lower = 0, upper =Inf)$value)
}


median(rho)
quantile(rho, probs = c(.025, .975))


#CFR by location

selectedlocs <- vector(length = cfr_moddata$L)
rhoi <- matrix(nrow=length(lambda1), ncol = length(selectedlocs))
for(j in 1:cfr_moddata$L){
  for(i in 1:length(lambda1i[,j])){
  try (
    rhoi[i,j] <- integrate(function(x) {   
                                         risk.Inf <- alpha1[i]*lambda1i[i,j]*x^(alpha1[i]-1)*exp(- ((lambda1i[i,j]*x^(alpha1[i]) +lambda2i[i,j]*x^(alpha2[i]))))
                                          return(risk.Inf)
    },
                        lower = 0, upper =Inf)$value)
}
}

rhoj <- vector(length = cfr_moddata$L)
for(j in 1:cfr_moddata$L){
  rhoj[j] <- median(rhoi[,j])
}
names(rhoj) <- names(locs[-c(201)])

rhoj


 plot((lambda2), type = "l")


```


### Run compartmental model
Define model
```{stan, eval = FALSE, output.var="cfrmdl_erlang"}
//Really not properly erlang...need to think about what this means...
data {
  int <lower=0> T; //the number of time steps included
  int <lower=0> L; //the number of locations we have data from
  int <lower=0> r[T,L]; //  number of recovered cases reported on each day.
  int <lower=0> d[T,L]; //  number of deaths reported on each day. 
  real <lower=0> c[T,L]; //number of new confirmed cases on each day. 
  int w[L]; //is this wuhan
  int N; //the numberof compartments.
  int Nd; //the numberof deaths (individual)
  int Nr; // number of individual recovs
  int td[Nd];
  int tr[Nr];
 // matrix[Nd, 300] dt; // time to each individual deaths
 // matrix[Nr, 300] dr; //time to each individual recoveries
}

parameters {
  real <lower=0, upper=1> lambda1[N]; //death rate per compartment
  real <lower=0, upper=1> lambda2[N]; //recovery rate per compartment
  //real  logitlambda1[N]; //log death rate per compartment
  //real  logitlambda2[N]; //log recovery rate per compartment
  real <lower=0, upper=1> alpha; //rate of movement between compartments .
  real delta_death_hubei; // wuhan detect rate
  real delta_recover_hubei; // wuhan detect rate

}

transformed parameters {
 // real <lower=0> lambda1[N]; //death rate per compartment
 // real <lower=0> lambda2[N]; //recovery rate per compartment
  real <lower=0> expected_deaths[T,L]; //  # deaths at time T
  real <lower=0> expected_recovereds[T,L]; //  # those who have exited due to recovery at T
  real <lower=0> expected_riskset[T,L,N]; // expected people in each compartment at eahc time.
  real <lower=0> indiv_expected_risk [300,N]; //looking a very long way out where would we expect an individual to be
  real <lower=0> indiv_expect_death [300]; //what is an indivduals probability of dying on exactly each day
  real <lower=0> indiv_expect_recover [300]; //what is an individauls probability of recovering on each day
  
  //lambda1 = 1/(1+exp(-logitlambda1));
  //lambda2 = 1/(1+exp(-logitlambda2));
  
//Fill in the probability of getting infected on each day 
for (i in 1:N) {
  indiv_expected_risk[1,i] = 0;
}

indiv_expected_risk[1,1] = 1;
indiv_expect_death[1] = indiv_expected_risk[1,1]*lambda1[1];
indiv_expect_recover[1] = indiv_expected_risk[1,1]*lambda2[1];

for (t in 2:300) {
  indiv_expected_risk[t,1] =  
    indiv_expected_risk[t-1,1]  - 
    indiv_expected_risk[t-1,1] * lambda1[1] -
    indiv_expected_risk[t-1,1] * lambda2[1];
  if (N>1) {
    for (i in 2:N) {
      indiv_expected_risk[t,i-1] -= 
        alpha *indiv_expected_risk[t-1,i-1];
      
      indiv_expected_risk[t,i] =  
        indiv_expected_risk[t-1,i] +
        alpha *indiv_expected_risk[t-1,i-1] -
        indiv_expected_risk[t-1,i] * lambda1[i] -
        indiv_expected_risk[t-1,i] * lambda2[i];
    }
  }
  
  //Accumulate deaths and recovereds                      
  indiv_expect_death[t] = indiv_expected_risk[t,1] * lambda1[1];
  indiv_expect_recover[t] = indiv_expected_risk[t,1] * lambda2[1];
  
  if(N>1) {
    for (i in 2:N) {
      indiv_expect_death[t] += indiv_expected_risk[t,i] * lambda1[i];
      indiv_expect_recover[t] += indiv_expected_risk[t,i] * lambda2[i];
    }
  }
}


  
//Calculation the popualtion based probabilities. 
for (j in 1:L) {
    //initialize the 
    expected_riskset[1,j,1] = c[1,j]+0.001;
    expected_deaths[1,j] = expected_riskset[1,j,1] *
          lambda1[1] * exp(delta_death_hubei *w[j]) + 0.0001 ;
    expected_recovereds[1,j] = expected_riskset[1,j,1] *
        lambda2[1] * exp(delta_recover_hubei * w[j]) + 0.0001;
    
    //Initialize the riskset i ther compartments to 0 if they exist.
    if(N>1) {
      for (i in 2:N) {
        expected_riskset[1,j,i] = 0;
      }
    }
 
    for (t in 2:T) {
       //Move deaths and recoveries from last timestep out of first compartment.
       expected_riskset[t,j,1] =  expected_riskset[t-1,j,1] + c[t,j] - 
                                  expected_riskset[t-1,j,1] * lambda1[1] * exp(delta_death_hubei *w[j]) - 
                                  expected_riskset[t-1,j,1] * lambda2[1] * exp(delta_recover_hubei * w[j]);
                                
      if(N>1) {
        for (i in 2:N) {
          //remove the alpha from the expected risk set i-1
          expected_riskset[t,j,i-1] -= alpha *expected_riskset[t-1,j,i-1];
          
          expected_riskset[t,j,i] =  expected_riskset[t-1,j,i] +
                                     alpha *expected_riskset[t-1,j,i-1] -
                                     expected_riskset[t-1,j,i] * lambda1[i] * exp(delta_death_hubei *w[j])-
                                     expected_riskset[t-1,j,i] * lambda2[i] * exp(delta_recover_hubei * w[j]);
        }
      }                            
      
      //Accumulate deaths and recovereds                      
      expected_deaths[t,j] = expected_riskset[t,j,1] * lambda1[1] * exp(delta_death_hubei *w[j]) + 0.0001 ;
      expected_recovereds[t,j] = expected_riskset[t,j,1] * 
              lambda2[1] * exp(delta_recover_hubei * w[j])  + 0.0001;
              
      if(N>1) {
        for (i in 2:N) {
          expected_deaths[t,j] += expected_riskset[t,j,i] * lambda1[i] * exp(delta_death_hubei *w[j]);
          expected_recovereds[t,j] += expected_riskset[t,j,i] * 
                lambda2[i] * exp(delta_recover_hubei * w[j]);
        }
      }
      
    }
  }
}


model {

  delta_death_hubei ~ normal(0,.5); //somewhat stron prior around 0
  delta_recover_hubei ~ normal(0,.5); //somewhat stron prior around 0
  //definitely can be made more effcient.
  for (j in 1:L) {
    for (t in 1:T) {
      target+=poisson_lpmf(d[t,j]|expected_deaths[t,j]) +
            poisson_lpmf(r[t,j]|expected_recovereds[t,j]);
    }
  }

    for (g in 1:Nd) {
      target+=log(indiv_expect_death[td[g]]);
      }
    for (h in 1:Nr){
      target+= log(indiv_expect_recover[tr[h]]);
    }
  
 
}

```

Run compartmental model
```{r, eval=FALSE}
initval <- function(){
  l1 <- c(.01, .01, .01)
  l2 <- c(.05, .05, .05)
  al <- 0.5
    params <- list(lambda1=l1, lambda2=l2, alpha=al, delta_death_hubei = 0, delta_recover_hubei=0)
    params
    #list(params, params, params, params)
}

initval()
  cfrmdl_erlang_data <- cfr_moddata
  cfrmdl_erlang_data$N <- 3 #Set the number of compartments
  cfrmdl_erlang_res <- sampling(cfrmdl_erlang, data=cfrmdl_erlang_data, 
                         iter=200,  init = initval, cores = detectCores()) #
  
  

```

Get CFR
```{r}
##Translate this into estimates of the CFR, rho
N <- cfrmdl_erlang_data$N

##' Param 1 is alpha.
##' Param 2:(N+1) are lambda 1s
##' State N+1 is dead, state N+2 is recovered
dx.dt <- function (t, state, param) {
  rc <- vector(length=N+2)
  rc[N+1] <- 0
  rc[N+2] <- 0
  
  for (i in 1:N) {
    ##add from last state if not 1
     rc[i] <- ifelse(i>1, state[i-1]*param[1], 0) 
     ## Take out deaths and recoverds
     rc[i] <- rc[i] - (param[i+1] + param[N+i+1])*state[i]
     ##Move to next state if not N
     if (i<N) {rc[i] <- rc[i]-param[1]*state[i]}
     ##Decrement deaths and revoverds
     rc[N+1] <- rc[N+1] + param[i+1]*state[i]
     rc[N+2] <- rc[N+2] + param[N+i+1]*state[i]
  }
  
  return(list(rc))
}


require(deSolve)

solve_deaths <- function(alpha, lambda1s, lambda2s) {
  res <- ode(c(1, rep(0, N+1)), #initial state for N compartments plus death/recovery
             c(1,1000), #just need intial values and at T large
             dx.dt, #function
             c(alpha, lambda1s, lambda2s)
           )

  return(res[2,N+2]) #should be deaths
}

chains <- extract(cfrmdl_erlang_res)
rho_erlang <- vector(length=length(chains$alpha))
rho_erlang_hubei <- vector(length=length(chains$alpha))
i <- 1
lambda1 <- as.matrix(chains$lambda1)
lambda2 <- as.matrix(chains$lambda2)
for(i in 1:length(chains$alpha)){
  rho_erlang[i] <- solve_deaths(chains$alpha[i], lambda1[i,], lambda2[i,])
  
  rho_erlang_hubei[i] <- solve_deaths(chains$alpha[i], 
                                      lambda1[i,]*exp(chains$delta_death_hubei[i]), 
                                      lambda2[i,]*exp(chains$delta_recover_hubei[i]))
}


median(rho_erlang)
quantile(rho_erlang, probs = c(.025, .975))

median(rho_erlang_hubei)
quantile(rho_erlang_hubei, probs = c(.025, .975))
```
