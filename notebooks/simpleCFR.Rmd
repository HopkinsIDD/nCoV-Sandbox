---
title: 'Simple CFR approach'
output: html_document
---

```{r setup, include=FALSE}

#preamble
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "..")
 
require(knitr)
require(tidyverse)
require(gridExtra)
require(rstan)
require(splines2)
require(readr)
require(parallel)
require(mosaicCalc)
require(lubridate)

source("../R/DataLoadUtils.r")
source("../R/BasicEpiAnalyses.r")
source("../R/CFRutils.r")

```

## Goal
Here is the basic model. We are interested in estimating the CFR among confirmed 
cases, $\rho$. 

Presume that the time from confirmation to report of death (censoring at recovery) follows an arbitrary parametric distribution:
$$\Pr(Y_i<k) = F(k; \theta)$$

Where $Y_i$ is the time from confirmation to  death for person $i$ and $\theta$ is a vector of parameters required to define the parametric distribution..

Moreover, the time from confirmation to death or recovery (composite outcome) follows an exponential distribution:
$$\Pr(T_i<k) = G(k; \eta)$$
Where $T_i$ is the time from confirmation to  death or recovery for person $i$.



Let $d_{jt}$ be the number of new reported deaths in location $j$ on calendar date $t$. $d_{jt}$ depends on the hazard function for death over time since becoming a confirmed case and the distribution of infection duration on calendar date $t$.
$$E(d_{jt}) = \sum_{k=1}^t n_{jtk}h_{1k}$$

where $h_{1k}$ is the cause-specific hazard function for death over time since confirmation, and whose shape is determined by parameters $\theta$.


Let $r_{jt}$ be the number of new reported recoveries in location $j$ on calendar date $t$. $r_{jt}$ depends on the hazard function for recovery over time since becoming a confirmed case and the distribution of infection duration on calendar date $t$.
$$E(r_{jt}) = \sum_{k=1}^t n_{jtk}h_{2k}$$

where $h_{2k}$ is the cause-specific hazard function for recovery over time since confirmation, and whose shape is determined by parameters $\eta$.

For example, if we assume that $F{k}$ follows a Weibull distribution, $\theta = \{\lambda_1, \alpha_1\}$ and $h_{1k} = \alpha_1\lambda_1^{\alpha_1}k^{(\alpha_1-1)}$

To simplify estimation of $\rho$ in our dataset, which is organized by calendar date, we will first assume both time to death and time to recovery follow an exponential distirbution with a constant hazard functions, $\lambda_1$ and $\lambda_2$, respectively, for now. 

Based on the above:
$$E(d_{jt}) =  n_{jt} \lambda_1$$
where $n_{jt}$ is the number of currently infected people in the risk set on that day.
Similarly, let $r_{jt}$ be the number of new recoveries s in location $j$ on calendar date $t$. Based on the 
above:
$$E(r_{jt}) =  n_{jt} (\lambda_2) $$

Because there appear to be differences in mortality and recovery rates bewteen Hubei and elsewhere, we will write $\lambda_1$ and $\lamnbda_2$ as a function of location, such that $\lambda_1 = exp(\beta_0 + \beta_1 Hubei)$ and $\lambda_2 = exp(\gamma_0 + \gamma_1 Hubei)$.

## Assuming constant hazards of death and recovery
### Stan models
First, define the stan model assuming constant hazards for death and recovery over time.

```{stan, eval = FALSE, output.var="cfrmdl2"}

data {
  int <lower=0> T; //the number of time steps included
  int <lower=0> L; //the number of locations we have data from
  int <lower=0> r[T,L]; //  number of recovered cases reported on each day.
  int <lower=0> d[T,L]; //  number of deaths reported on each day. 
  real <lower=0> c[T,L]; //number of new cases  on each day. 
  int w[L]; //is this wuhan
  int Nd; // number of indiviudal-level deaths
  int Nr; // number of individual-level recoveries
  int wdi[Nd]; // indicator of living in hubei for individual deaths
  int wri[Nr]; // indicator of living in hubei for individual recoveries
  real td[Nd]; // time to each individual deaths
  real tr[Nr]; //time to each individual recoveries
}

parameters {
  real  loglambda1; //parameter for time to death distribution
  real  loglambda2; // parameter for time to recovery distribution
  real delta1_hubei; // parameter for difference in lambda1 in hubei
  real delta2_hubei; // parameter for difference in lambda2 in hubei
  real <lower= 0, upper=1> dr; // wuhan detect rate
}

transformed parameters {
  real <lower=0> expected_deaths[T,L]; //  # deaths at time T
  real <lower=0> expected_recovereds[T,L]; //  # those who have exited due to recovery at T
  real <lower=0> expected_riskset[T,L]; // expected people in risk set
  real <lower=0> lambda1i[Nd]; // lambda1 for each individual-level death
  real <lower=0> lambda2i[Nr]; //lmabda2 for each individual-level recovery

for (j in 1:L) {
    expected_riskset[1,j] = c[1,j];
    expected_deaths[1,j] = expected_riskset[1,j] * exp(loglambda1 + delta1_hubei*w[j]) + 0.0001 ;
    expected_recovereds[1,j] = expected_riskset[1,j] * exp(loglambda2 + delta2_hubei*w[j]) + 0.0001;
 
    for (t in 2:T) {
      expected_riskset[t,j] =  expected_riskset[t-1,j] + c[t,j] - 
                                expected_deaths[t-1,j] - expected_riskset[t-1,j] * exp(loglambda2 + delta2_hubei*w[j]);
      expected_deaths[t,j] = expected_riskset[t,j] * exp(loglambda1 + delta1_hubei*w[j]) + 0.0001 ;
      expected_recovereds[t,j] = expected_riskset[t,j] * exp(loglambda2 + delta2_hubei*w[j]) + 0.0001;
      
    }
  }
  for (i in 1:Nd){
  lambda1i[i] = exp(loglambda1 + delta1_hubei*wdi[i]);
}
  for (g in 1:Nr){
   lambda2i[g] = exp(loglambda2 + delta2_hubei*wri[g]);
  }
}




model {
  //definitely can be made more effcient.
  for (j in 1:L) {
    for (t in 1:T) {
      target+=poisson_lpmf(d[t,j]|expected_deaths[t,j]) + poisson_lpmf(r[t,j]|expected_recovereds[t,j]);
    }
  }
 for (i in 1:Nd){
  target+=exponential_lpdf(td[i]|lambda1i[i]);
 }
  for (g in 1:Nr){
  target+=exponential_lpdf(tr[g]|lambda2i[g]);
 }
}

```

### Data management
Prepare aggregate data on total cases, deaths, and recoveries by calendar date to be read into model.  

```{r message=FALSE, warning=FALSE, include=FALSE}
library(readr)
library(tidyverse)
#Load in the JHU CSSE Data
todaydate <- ISOdate(2020,2,25, hour = 11, min = 59, tz = "UTC")
cfr_moddata <- moddata(todaydate, withHubei = TRUE)
#(cfr_moddata, file = "cfr_moddata.RData")

#prepare individual-level data
date <-ymd("20200214")
IndDat <- read_MK_linelist("2-14-2020")
IndDat <- process_MK_linelist(IndDat, ymd(date))

IndDat <- IndDat %>% 
            mutate(t = ifelse(t<=0, 1, t)) 

deaths <- IndDat %>% filter(delta == 1 & !is.na(t)) %>% select(t, province)
recovs <-   IndDat %>% filter(delta == 2& !is.na(t)) %>% select(t, province)
td <- deaths$t
wdi <- ifelse(deaths$province != "Hubei" | is.na(deaths$province), 0, 1)
tr <- recovs$t
wri <- ifelse(recovs$province != "Hubei" | is.na(recovs$province), 0, 1)

cfr_moddata$tr <- tr
cfr_moddata$td <- td
cfr_moddata$wdi <- wdi
cfr_moddata$wri <- wri
cfr_moddata$Nd <- length(td)
cfr_moddata$Nr <- length(tr)
```

### Run Exponential model

```{r, eval = FALSE}
  cfrmdl_res_ex <- sampling(cfrmdl2, data=cfr_moddata,
                         iter=2000, cores = 4, chains = 4)
  chains <- extract(cfrmdl_res_ex)
  lambda1 <- exp(chains$loglambda1)
  lambda2 <- exp(chains$loglambda2)
  lambda1_hubei <- exp(chains$loglambda1 + chains$delta1_hubei)
  lambda2_hubei <- exp(chains$loglambda2 + chains$delta2_hubei)
  
  outdat <- data.frame(lambda1 = lambda1, lambda2 = lambda2, lambda1_hubei = lambda1_hubei, lambda2_hubei = lambda2_hubei)
  
  save(outdat, file = "data/outdat.RData")

```

### Summarize Exponential model


```{r, echo = FALSE }
load("data/outdat.RData")

lambda2 <- outdat[,2]
lambda1 <- outdat[,1] 
lambda2_hubei <- outdat[,4]
lambda1_hubei <- outdat[,3] 

# plots about lambda (turn on if necessary)
# plot(density(lambda1), xlim=c(0,.1), type = "l")
#  lines(density(lambda2))
#  plot(lambda2, type = "l")
#  plot(lambda1, type = "l")
 
 rho <- matrix(nrow = length(lambda1))
 #estimate rho outside hubei
for(i in 1:length(lambda1)){
    F <- antiD( ((h1 )  *  exp(-(( (h1) + (h2))  * x)))~x, h1 = lambda1[i], h2 = lambda2[i])
    rho[i] = F(x=Inf) - F(x=0)
}
rho <- rho[!is.na(rho)]
median(rho)



#  
# for(i in 1:length(lambda1)){
# 
#   try (
#     rho[i] <- integrate(function(x) {lambda1[i]*exp(-((lambda1[i]+lambda2[i])*x))}, 
#                         lower = 0, upper = Inf)$value)
# }
# 
# rho <- rho[!is.na(rho)]
# 
# #rho for outside hubei
# median(rho)
quantile(rho, probs = c(.025, .975))

# plot(density(rho))
# plot(log(rho), type = "l")


 #then estimate rho for hubei
 rho_hubei <- matrix(nrow = length(lambda1_hubei))

 #estimate rho outside hubei
for(i in 1:length(lambda1_hubei)){
    F <- antiD( ((h1 )  *  exp(-(( (h1) + (h2))  * x)))~x, h1 = lambda1_hubei[i], h2 = lambda2_hubei[i])
    rho_hubei[i] = F(x=Inf) - F(x=0)
}
rho_hubei <- rho_hubei[!is.na(rho_hubei)]
median(rho_hubei)

# 
# for(i in 1:length(lambda1)){
# 
#   try (
#     rho_hubei[i] <- integrate(function(x) {lambda1_hubei[i]*exp(-((lambda1_hubei[i]+lambda2_hubei[i])*x))}, 
#                         lower = 0, upper = Inf)$value)
# }
# 
# 
# rho_hubei <- rho_hubei[!is.na(rho_hubei)]
# median(rho_hubei)
quantile(rho_hubei, probs = c(.025, .975))
# plot(density(rho_hubei))
 plot(log(lambda1), type = "l")

```

## Allow hazard to vary over large time periods 

### Stan model for piecewise exponential model
Need to figure out why this is not working (it was when compartments were hardcoded)
```{stan, eval = FALSE, output.var="cfrmdl_pw"}

data {
  int <lower=0> T; //the number of time steps included
  int <lower=0> L; //the number of locations we have data from
  int <lower = 0> V; // max infection duration (may not be needed)
  int <lower=0> r[T,L]; //  number of recovered cases reported on each day.
  int <lower=0> d[T,L]; //  number of deaths reported on each day. 
  real <lower=0> c[T,L]; //number of new cases  on each day. 
  int w[L]; //is this wuhan
  int N; //the numberof compartments.
  int indices[V]; //vector of integer indices indicating which hazard people on each day are subject to
}

parameters {
  real loglambda1[N]; //parameter for time to death distribution
  real loglambda2[N]; // parameter for time to death or recovery distribution
  real delta1_hubei; //parameter for diff in hubei's lambda1
  real delta2_hubei; // parameter for diff in hubei's lambda2
}
transformed parameters {
  real <lower=0> expected_deaths[T,L]; //  # deaths at time T
  real <lower=0> expected_recovereds[T,L]; //  # those who have exited due to recovery at T
  matrix<lower=0>[V,T] expected_riskset; //expected risk set on each day of inf dur
  vector<lower=0>[N] h1;
  vector<lower=0>[N] h2;
 // vector[V] h1k;
 // vector[V] h2k;
  //real <lower=0> h1[V] ;
  //real <lower=0> h2[V];

for (j in 1:L) {
  // initialize expected_riskset to all 0s;
    expected_riskset = rep_matrix(0.0, V, T);
    h1 = rep_vector(0, N); // or N
    h2 = rep_vector(0, N); // or N
 //   for(k in 1:V){ //pre-compute hazards for each day of inf dur (do dno't have to do within each loop!)
 //       for(h in 1:N){
 //       h1[k] += exp(loglambda1[h] + delta1_hubei*w[j])*(((T/N)*(h-1))<k<=((T/N)*h));
 //       h2[k] += exp(loglambda2[h] + delta2_hubei*w[j])*(((T/N)*(h-1))<k<=((T/N)*h));
 //       }
 //     }
    if(N==1){
      h1[1] = exp(loglambda1[1] + delta1_hubei*w[j]);
      h2[1] = exp(loglambda2[1] + delta2_hubei*w[j]);
    }
    if(N>1){
      for(h in 1:N){ //pre-compute hazards for each  interval (do dno't have to do within each loop!)
      h1[h] = exp(loglambda1[h] + delta1_hubei*w[j]);
      h2[h] = exp(loglambda2[h] + delta2_hubei*w[j]);
    }
    }

    
    expected_riskset[1,1] = c[1,j]+0.0001; //risk set on day 1 at inf duration 1 is just c1
    expected_deaths[1,j] = expected_riskset[1,1] * h1[1] + 0.0001 ;
    expected_recovereds[1,j] = expected_riskset[1,1] * h2[1] + 0.0001;
 

    for (t in 2:T) {
      expected_riskset[1,t] = c[t,j]+0.0001;
      expected_deaths[t,j] = expected_riskset[1,t] *  h1[1] + 0.0001 ;
      expected_recovereds[t,j] = expected_riskset[1,t] *  h2[1] + 0.0001;
      
      //fix this section to allow for arbitrary number of compartments (right now just 3)
      for(k in 2:t){
        expected_riskset[k,t] = (expected_riskset[k-1,t-1] - 
                                (expected_riskset[k-1,t-1]*h1[indices[k-1]] +  
                                (expected_riskset[k-1,t-1]*h2[indices[k-1]]))+0.0001);
        expected_deaths[t,j] +=  (expected_riskset[k,t] * h1[indices[k]]);
        expected_recovereds[t,j] += (expected_riskset[k,t] * h2[indices[k]]);

      }
    
    }
  }
}

model {
  //definitely can be made more effcient.
  for (j in 1:L) {
    for (t in 1:T) {
      target+=poisson_lpmf(d[t,j]|expected_deaths[t,j]) + poisson_lpmf(r[t,j]|expected_recovereds[t,j]);
    }
  }
 
}

```


### Run and summarize piecewise exponential model
```{r, eval = FALSE}
cfr_moddata_pw <- cfr_moddata
cfr_moddata_pw$N <- 2
cfr_moddata_pw$indices <- vector(length = cfr_moddata_pw$V)
for(j in 1:length(cfr_moddata_pw$indices)){
  for(i in 1:cfr_moddata_pw$N){
    cfr_moddata_pw$indices[j] <- sum(((((cfr_moddata_pw$T/cfr_moddata_pw$N)*(i-1))<j) & (j<=((cfr_moddata_pw$T/cfr_moddata_pw$N)*i)))*i, cfr_moddata_pw$indices[j])
  }
}

  cfrmdl_res <- sampling(cfrmdl_pw, data=cfr_moddata_pw,
                         iter=3000, chains = 6, cores = 6)
  chains <- extract(cfrmdl_res)
  lambda1 <- as.matrix(exp(chains$loglambda1))
  lambda2 <- as.matrix(exp(chains$loglambda2))
  lambda1_hubei <- as.matrix(exp(apply(chains$loglambda1, 2, function(x) x + chains$delta1_hubei)))
  lambda2_hubei <- as.matrix(exp(apply(chains$loglambda2, 2, function(x) x + chains$delta2_hubei)))
  
  #estimate rho outside hubei
  
rho <- matrix(nrow = nrow(lambda1))
T <- (cfr_moddata_pw$T)
N <- cfr_moddata_pw$N

#need to adapt this for an arbitrary number of compartments
for(i in 1:nrow(lambda1)){

  try (
    rho[i] <- integrate(function(x) {
      (lambda1[,1][i] * (x<T/N) + lambda1[,2][i] * ((T/N<x) & (x<(2*T/N))))  * exp(-(( (lambda1[,1][i]*(x<T/N)+lambda1[,2][i] * ((T/N<x) & (x<(2*T/N))))
              + (lambda2[,1][i]*(x<T/N)+lambda2[,2][i]*((T/N<x) & (x<(2*T/N))))) 
              * x)
             )} , lower = 0, upper = Inf)$value)
}
rho <- rho[!is.na(rho)]
median(rho)
quantile(rho, probs = c(.025, .975))

#estimate rho in hubei

rho_hubei <- matrix(nrow = nrow(lambda1))
for(i in 1:nrow(lambda1)){

  try (
    rho_hubei[i] <- integrate(function(x) {
      (lambda1_hubei[,1][i] * (x<T/N) + lambda1_hubei[,2][i] * ((T/N<x) & (x<(2*T/N))))  * exp(-(( (lambda1_hubei[,1][i]*(x<T/N)+lambda1_hubei[,2][i] * ((T/N<x) & (x<(2*T/N))))
              + (lambda2_hubei[,1][i]*(x<T/N)+lambda2_hubei[,2][i]*((T/N<x) & (x<(2*T/N)))) 
              * x)
             ))} , lower = 0, upper = Inf)$value)
}

rho_hubei <- rho_hubei[!is.na(rho_hubei)]
median(rho_hubei)
quantile(rho_hubei, probs = c(.025, .975))


plot(density(lambda1[,1]), xlim=c(0,.1), type = "l")
 lines(density(lambda2[,1]))
 plot(log(lambda1[,1]), type = "l")
 plot(log(lambda2[,1]), type = "l")
```

## Allow hazard to vary by day of infection

### Stan model for Weibull

Now, attempt to allow hazards to vary over time assuming times to death and recovery follow Weibull distributions
```{stan, eval = FALSE, output.var="cfrmdl_wbl"}

data {
  int <lower=0> T; //the number of time steps included
  int <lower=0> L; //the number of locations we have data from
  int <lower = 0> V; // max infection duration (may not be needed)
  int <lower=0> r[T,L]; //  number of recovered cases reported on each day.
  int <lower=0> d[T,L]; //  number of deaths reported on each day. 
 //  int <lower=0> dr[T,L]; //  number of deaths reported on each day. 
  real <lower=0> c[T,L]; //number of new cases  on each day. 
  int w[L]; //is this wuhan
    int Nd; // number of indiviudal-level deaths
  int Nr; // number of individual-level recoveries
  int wdi[Nd]; // indicator of living in hubei for individual deaths
  int wri[Nr]; // indicator of living in hubei for individual recoveries
  real td[Nd]; // time to each individual deaths
  real tr[Nr]; //time to each individual recoveries
}

parameters {
  real loglambda1; //parameter for time to death distribution
  real loglambda2; // parameter for time to death or recovery distribution
   //real loglambda; // parameter for time to death or recovery distribution
  real delta1_hubei; //parameter for diff in hubei's lambda1
  real delta2_hubei; // parameter for diff in hubei's lambda2
  //real delta_hubei; // parameter for diff in hubei's lambda2
  real  logalpha1; //parameter for time to death distribution
  real  logalpha2; // parameter for time to death or recovery distribution
  // real  logalpha; // parameter for time to death or recovery distribution
 // real <lower=0> invalpha1; //parameter for time to death distribution
  //real  <lower=0> invalpha2; // parameter for time to death or recovery distribution
}
transformed parameters {
  real <lower=0> expected_deaths[T,L]; //  # deaths at time T
  real <lower=0> expected_recovereds[T,L]; //  # those who have exited due to recovery at T
 // real <lower=0> expected_rds[T,L]; //  # those who have exited due to recovery at T
  matrix[V,T] expected_riskset; //expected risk set on each day of inf dur
  vector[V] h1;
  vector[V] h2;
  // vector[V] hall;
  real <lower=0> alpha1; //parameter for time to death distribution
 real <lower=0> alpha2; // parameter for time to death or recovery distribution
 real <lower=0> lambda1i[Nd]; // lambda1 for each individual-level death
  real <lower=0> lambda2i[Nr]; //lmabda2 for each individual-level recovery
 //real <lower=0> alpha;
  alpha1 = exp(logalpha1);
  alpha2 = exp(logalpha2);
  // alpha = exp(logalpha);




for (j in 1:L) {
  // initialize expected_riskset to all 0s;
    expected_riskset = rep_matrix(0.0, V, T);
    h1 = rep_vector(0, V);
    h2 = rep_vector(0, V);
   //  hall = rep_vector(0, V);
    for(h in 1:V){ //pre-compute hazards at each time (do dno't have to do within each loop!)
      h1[h] = alpha1*exp(loglambda1 + delta1_hubei*w[j])*h^(alpha1-1);
      h2[h] = alpha2*exp(loglambda2 + delta2_hubei*w[j])*h^(alpha2-1);
    //  hall[h] = alpha*exp(loglambda + delta_hubei*w[j])*h^(alpha-1);
    }

    expected_riskset[1,1] = c[1,j]+0.0001; //risk set on day 1 at inf duration 1 is just c1
    expected_deaths[1,j] = expected_riskset[1,1] * h1[1] + 0.0001 ;
    expected_recovereds[1,j] = expected_riskset[1,1] * h2[1] + 0.0001;
   //  expected_rds[1,j] = expected_riskset[1,1] * hall[1] + 0.0001;
 

    for (t in 2:T) {
      expected_riskset[1,t] = c[t,j]+0.0001;
      expected_deaths[t,j] = expected_riskset[1,t] *  h1[1] + 0.0001 ;
      expected_recovereds[t,j] = expected_riskset[1,t] *  h2[1] + 0.0001;
      // expected_rds[t,j] = expected_riskset[1,t] *  hall[1] + 0.0001;
      
      for(k in 2:t){
      
        expected_riskset[k,t] = (expected_riskset[k-1,t-1] - (expected_riskset[k-1,t-1]*h1[k-1] +  (expected_riskset[k-1,t-1]* h2[k-1]))+0.0001);
       
       // expected_riskset[k,t] = (expected_riskset[k-1,t-1] - (expected_riskset[k-1,t-1]*hall[k-1] )+0.0001);
        expected_deaths[t,j] +=  (expected_riskset[k,t] * h1[k]);
        expected_recovereds[t,j] += (expected_riskset[k,t] * h2[k]);
       //  expected_rds[t,j] += (expected_riskset[k,t] * hall[k]);

      }
    }
  }

 for (i in 1:Nd){
  lambda1i[i] = exp(loglambda1 + delta1_hubei*wdi[i]);
}
  for (g in 1:Nr){
   lambda2i[g] = exp(loglambda2 + delta2_hubei*wri[g]);
  }
}





model {
  //definitely can be made more effcient.
  for (j in 1:L) {
    for (t in 1:T) {
      target+=poisson_lpmf(d[t,j]|expected_deaths[t,j]) + poisson_lpmf(r[t,j]|expected_recovereds[t,j]);
    }
  }
 for (i in 1:Nd){
  target+=weibull_lpdf(td[i]|alpha1, lambda1i[i]);
 }
  for (g in 1:Nr){
  target+=weibull_lpdf(tr[g]|alpha2, lambda2i[g]);
 }
}
```


### Run Weibull model

```{r, eval = FALSE}
#cfr_moddata$dr <- cfr_moddata$d+cfr_moddata$r
  cfrmdl_res_Wbl <- sampling(cfrmdl_wbl, data=cfr_moddata,
                         iter=2000, cores = detectCores())
  chains <- rstan::extract(cfrmdl_res_Wbl)
  lambda1 <- exp(chains$loglambda1)
  lambda2 <- exp(chains$loglambda2)
 #  lambda <- exp(chains$loglambda)
  lambda1_hubei <- exp(chains$loglambda1 + chains$delta1_hubei)
 lambda2_hubei <- exp(chains$loglambda2 + chains$delta2_hubei)
#   lambda_hubei <- exp(chains$loglambda + chains$delta_hubei)
  alpha1 <- chains$alpha1
  alpha2 <- chains$alpha2
  #  alpha <- chains$alpha
   outdat_wbl <- data.frame(lambda1 = lambda1, lambda2 = lambda2, lambda1_hubei = lambda1_hubei, lambda2_hubei = lambda2_hubei, alpha1 = alpha1, alpha2 = alpha2)
  # 
   save(outdat_wbl, file = "data/outdat_wbl.RData")
```

### Summarize Weibull model

```{r, echo = FALSE }
load("data/outdat_wbl.RData")

lambda2 <- outdat_wbl[,2]
lambda1 <- outdat_wbl[,1] 
lambda2_hubei <- outdat_wbl[,4]
lambda1_hubei <- outdat_wbl[,3] 
alpha1 <- outdat_wbl[,5]
alpha2 <- outdat_wbl[,6]


#first estimate rho outside hubei
rho_wbl <- matrix(nrow = length(lambda1))

 for(i in 1:length(lambda1)){
  try (
    rho_wbl[i] <- integrate(function(x) {   
                                          risk.Inf <- alpha1[i]*lambda1[i]*x^(alpha1[i]-1)*exp(- ((lambda1[i]*x^(alpha1[i]) +lambda2[i]*x^(alpha2[i]))))
                                          return(risk.Inf)
    },
                        lower = 0, upper =100)$value)
}

rho_wbl <- rho_wbl[!is.na(rho_wbl)]
median(rho_wbl)
quantile(rho_wbl, probs = c(.025, .975))

#then estimate rho in hubei
rho_wbl_hubei <- matrix(nrow = length(lambda1_hubei))

 for(i in 1:length(lambda1_hubei)){
  try (
    rho_wbl_hubei[i] <- integrate(function(x) {   
                                          risk.Inf <- alpha1[i]*lambda1_hubei[i]*x^(alpha1[i]-1)*exp(- ((lambda1_hubei[i]*x^(alpha1[i]) +lambda2_hubei[i]*x^(alpha2[i]))))
                                          return(risk.Inf)
    },
                        lower = 0, upper =100)$value)
 }



rho_wbl_hubei <- rho_wbl_hubei[!is.na(rho_wbl_hubei)]
median(rho_wbl_hubei)
quantile(rho_wbl_hubei, probs = c(.025, .975))

#diagnostic plots
 plot((alpha2), type = "l")#, ylim = c(0,.00000000001))
  plot((lambda1), type = "l")
plot((rho_wbl), type = "l")
# plot((lambda2), type = "l")#, ylim =c( 0, 100000))


#parking lot for stuff that didn't work
# 
# for(i in 1:length(lambda1)){
#   try (
#     rho_wbl_hubei[i] <- integrate(function(x){alpha1[i]*lambda1_hubei[i]*x^(alpha1[i]-1)*exp(-(alpha1[i]*lambda1_hubei[i]*x^(alpha1[i]-1)+alpha2[i]*lambda2_hubei[i]*x^(alpha2[i]-1))*x)},
#                         lower = 0, upper = Inf)$value)
# }

 
#  for(i in 1:length(lambda1)){
#   try (
#     rho_wbl[i] <- integrate(function(x) {   
#                                           risk.Inf <- alpha1[i]*lambda1[i]*x^(alpha1[i]-1)
#                                     *exp(- ((alpha1[i]*lambda1[i]*x^(alpha1[i]-1)
#                                              +alpha2[i]*lambda2[i]*x^(alpha2[i]-1))*x))
#                                           return(risk.Inf)
#     },
#                         lower = 0, upper =100)$value)
# }



# rho_wbl <- matrix(nrow = length(lambda1))
# rho_wbl_h <- matrix(nrow = length(lambda1))
# for(i in 1:length(lambda1)){
#   #outside hubei
#   # F <- antiD( ((alph1*lam1^alph1*x^(alph1-1) )  *  exp(-(((lam2*x)^alph2)))  )~x, 
#   #             alph1=alpha1[i], lam1 = lambda1[i], lam2 = lambda[i], alph2 = alpha[i])
#   # rho_wbl[i] = F(x=Inf) - 0#F(x=0)
# 
#     F <- antiD( ((alph1*lam1^alph1*x^(alph1-1) )  *  exp(-(( ((alph1*lam1^alph1*x^(alph1-1) )*x)^alph1 + ((alph2*lam2*x^(alph2-1) )*x)^alph2)))  )~x,
#               alph1=alpha1[i], lam1 = lambda1[i], lam2 = lambda2[i], alph2 = alpha2[i])
# 
#   rho_wbl[i] = F(x=Inf)  #- 0#F(x=0)
# 
#   # hubei
#   Fh <- antiD( ((alph1*lam1^alph1*x^(alph1-1) )  *  exp(-(( ((alph1*lam1^alph1*x^(alph1-1) )*x^alph1) + ((alph2*lam2^alph2*x^(alph2-1) )*x^alph2)))  ))~x, 
#               alph1=alpha1[i], lam1 = lambda1_hubei[i], lam2 = lambda2_hubei[i], alph2 = alpha2[i])
#   rho_wbl_h[i] = Fh(x=Inf) - 0#F(x=0)
#   
# }
#  
#   median(rho_wbl)
#   median(rho_wbl_h)


```


### Stan model for Lognormal

Now, attempt to allow hazards to vary over time assuming times to death and recovery follow lognormal distributions
```{stan, eval = FALSE, output.var="cfrmdl_ln"}

data {
  int <lower=0> T; //the number of time steps included
  int <lower=0> L; //the number of locations we have data from
  int <lower = 0> V; // max infection duration (may not be needed)
  int <lower=0> r[T,L]; //  number of recovered cases reported on each day.
  int <lower=0> d[T,L]; //  number of deaths reported on each day. 
  real <lower=0> c[T,L]; //number of new cases  on each day. 
  int w[L]; //is this wuhan
      int Nd; // number of indiviudal-level deaths
  int Ntot; // number of individual-level deaths or recoveries
  int wdi[Nd]; // indicator of living in hubei for individual deaths
  int wrdi[Ntot]; // indicator of living in hubei for individual deaths or recoveries
  real td[Nd]; // time to each individual deaths
  real tall[Ntot]; //time to death or recovery (for all deaths+recoveries)
}

parameters {
  real logmu1; //parameter for time to death distribution
  real logmuall; // parameter for time to death or recovery distribution
  real delta1_hubei; //parameter for diff in hubei's lambda1
  real delta_hubei; // parameter for diff in hubei's lambda2
  real <lower=0> sigma1; //parameter for time to death distribution
  real <lower=0> sigma; // parameter for time to death or recovery distribution
}
transformed parameters {
  real <lower=0> expected_deaths[T,L]; //  # deaths at time T
  //real <lower=0> expected_recovereds[T,L]; //  # those who have exited due to recovery at T
   real <lower=0> expected_rds[T,L]; // deaths + recovereds
  matrix[V,T] expected_riskset; //expected risk set on each day of inf dur
  vector[V] h1;
 // vector[V] h2;
  vector[V] hall;
  real logmu1i[Nd]; // logmu1 for individual deaths
  real logmu2i[Ntot]; // logmu2 for individual deaths
  
for (j in 1:L) {
  // initialize expected_riskset to all 0s;
    expected_riskset = rep_matrix(0.0, V, T);
    h1 = rep_vector(0, V);
    hall = rep_vector(0, V);
    for(h in 1:V){ //pre-compute hazards at each time (do dno't have to do within each loop!)
      h1[h] = (exp(normal_lpdf(log(h)|(logmu1+delta1_hubei*w[j]), sigma1))/h)/(1 - normal_cdf(log(h), (logmu1+delta1_hubei*w[j]), sigma1));
       //h2[h] = (exp(normal_lpdf(log(h)|(logmu2+delta2_hubei), sigma2))/h)/(1 - normal_cdf(log(h), (logmu2+delta2_hubei), sigma2));
      hall[h] = (exp(normal_lpdf(log(h)|(logmuall+delta_hubei*w[j]), sigma))/h)/(1 - normal_cdf(log(h), (logmuall+delta_hubei*w[j]), sigma));
    }

    expected_riskset[1,1] = c[1,j]+0.0001; //risk set on day 1 at inf duration 1 is just c1
    expected_deaths[1,j] = expected_riskset[1,1] * h1[1] + 0.0001 ;
    //expected_recovereds[1,j] = expected_riskset[1,1] * h2[1] + 0.0001;
     expected_rds[1,j] = expected_riskset[1,1] * hall[1] + 0.0001;
 

    for (t in 2:T) {
      expected_riskset[1,t] = c[t,j]+0.0001;
      expected_deaths[t,j] = expected_riskset[1,t] *  h1[1] + 0.0001 ;
      expected_rds[t,j] = expected_riskset[1,t] *  hall[1] + 0.0001;
      
      for(k in 2:t){
      
        expected_riskset[k,t] = (expected_riskset[k-1,t-1] - (expected_riskset[k-1,t-1]*hall[k-1]))+0.0001;
        expected_deaths[t,j] +=  (expected_riskset[k,t] * h1[k]);
        expected_rds[t,j] += (expected_riskset[k,t] * hall[k]);

      }
    }
  }
 for (i in 1:Nd){
  logmu1i[i] = logmu1+delta1_hubei*wdi[i];
}
  for (g in 1:Ntot){
   logmu2i[g] = logmuall+delta_hubei*wrdi[g];
  }
}




model {
  //definitely can be made more effcient.
  for (j in 1:L) {
    for (t in 1:T) {
      target+=poisson_lpmf(d[t,j]|expected_deaths[t,j]) + poisson_lpmf(r[t,j]+d[t,j]|expected_rds[t,j]);
    }
  }
 for (i in 1:Nd){
  target+=lognormal_lpdf(td[i]|logmu1i[i], sigma1);
 }
  for (g in 1:Ntot){
  target+=lognormal_lpdf(tall[g]|logmu2i[g], sigma);
 }
}

```

### Prep data for lognormal model

```{r}
cfr_moddata$Ntot <- cfr_moddata$Nr+cfr_moddata$Nd
cfr_moddata$tall <- c(cfr_moddata$td, cfr_moddata$tr)
cfr_moddata$wrdi <- c(cfr_moddata$wdi, cfr_moddata$wri)

```
### Run lognormal model

```{r, eval = FALSE}
  cfrmdl_res_ln <- sampling(cfrmdl_ln, data=cfr_moddata,
                         iter=2000, cores = detectCores(), control = list(adapt_delta = 0.8))
  chains <- rstan::extract(cfrmdl_res_ln)
  logmu1 <- (chains$logmu1)
  logmuall <- (chains$logmuall)
  lmu1_hubei <- (chains$logmu1 + chains$delta1_hubei)
  lmu_hubei <- (chains$logmuall + chains$delta_hubei)
  sigma1 <- chains$sigma1
  sigma <- chains$sigma
  # outdat_ln <- data.frame(logmu1 = logmu1, logmu2 = logmu2, lmu1_hubei = lmu1_hubei, lmu2_hubei = lmu2_hubei, scale1 = scale1, scale2 = scale2)
  # 
  # save(outdat_ln, file = "data/outdat_ln.RData")
```

### Summarize Weibull model

```{r, echo = FALSE }
# load("data/outdat_wbl_noh.RData")
# 
# lambda2 <- outdat_wbl[,2]
# lambda1 <- outdat_wbl[,1] 
# lambda2_hubei <- outdat_wbl[,4]
# lambda1_hubei <- outdat_wbl[,3] 
# alpha1 <- outdat_wbl[,5]
# alpha2 <- outdat_wbl[,6]


rho_ln <- matrix(nrow = length(logmu1))
rho_ln_h <- matrix(nrow = length(logmu1))
for(i in 1:length(lambda1)){
  #outside hubei
  F <- antiD( ( (dlnorm(x, meanlog = logmu1, sdlog = sigma1)/x)/(1 - plnorm(x, meanlog= logmu1, sdlog = sigma1)) * (1 - plnorm(x, logmuall, sigma)))~x, 
              logmu1=logmu1[i], logmuall = logmuall[i], sigma1 - sigma1[i], sigma = sigma[i])
  rho_ln[i] = F(x=Inf) - 0#F(x=0)
  
  # hubei
 Fh <- antiD( ( (dlnorm(x, meanlog = logmu1, sdlog = sigma1)/x)/(1 - plnorm(x, meanlog= logmu1, sdlog = sigma1)) * (1 - plnorm(x, logmuall, sigma)))~x, logmu1=lmu1_hubei[i], logmuall = lmu_hubei[i], sigma1 = sigma1[i], sigma = sigma[i])
  rho_ln_h[i] = F(x=Inf) - 0#F(x=0)
  
}
 
  median(rho_ln)
  median(rho_ln_h)


#first estimate rho outside hubei
rho_wbl <- matrix(nrow = length(lambda1))
 h1x <- vector(length = length(lambda1))
 h2x <- vector(length = length(lambda1))
# for(i in 1:length(lambda1)){
#   try (
#     rho_wbl[i] <- integrate(function(x) {
#                                           h1x[i] <- alpha1[i]*lambda1[i]^alpha1[i]*x^(alpha1[i]-1)
#                                           h2x[i] <- alpha2[i]*lambda2[i]^alpha2[i]*x^(alpha2[i]-1)
#                                           risk.Inf <- h1x[i]*exp(-((h1x[i]+h2x[i])*x))
#                                           return(risk.Inf)
#     },
#                         lower = 0, upper =Inf)$value)
# }
 
 for(i in 1:length(lambda1)){
  try (
    rho_wbl[i] <- integrate(function(x) {   risk.Inf <- alpha1[i]*lambda1[i]^alpha1[i]*x^(alpha1[i]-1)*exp(-(( alpha1[i]*lambda1[i]^alpha1[i]*x^(alpha1[i]-1)+alpha2[i]*lambda2[i]^alpha2[i]*x^(alpha2[i]-1))*x))
                                          return(risk.Inf)
    },
                        lower = 0, upper =100)$value)
}

rho_wbl <- rho_wbl[!is.na(rho_wbl)]
median(rho_wbl)
quantile(rho_wbl, probs = c(.025, .975))

#then estimate rho in hubei
rho_wbl_hubei <- matrix(nrow = length(lambda1))
for(i in 1:length(lambda1)){
  try (
    rho_wbl_hubei[i] <- integrate(function(x) {alpha1[i]*lambda1_hubei[i]^alpha1[i]*x^(alpha1[i]-1)*exp(-(alpha1[i]*lambda1_hubei[i]^alpha1[i]*x^(alpha1[i]-1)+alpha2[i]*lambda2_hubei[i]^alpha2[i]*x^(alpha2[i]-1))*x)},
                        lower = 0, upper = Inf)$value)
}

rho_wbl_hubei <- rho_wbl_hubei[!is.na(rho_wbl_hubei)]
median(rho_wbl_hubei)
# quantile(rho_wbl_hubei, probs = c(.025, .975))
 plot((alpha1), type = "l")#, ylim = c(0,.00000000001))
  plot((logmu1), type = "l")#,  ylim = c(0,.00000000001))
plot((rho_wbl), type = "l")
# plot((lambda2), type = "l")#, ylim =c( 0, 100000))
```
